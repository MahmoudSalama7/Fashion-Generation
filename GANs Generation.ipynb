{"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5004740,"sourceType":"datasetVersion","datasetId":2903798}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import argparse\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom IPython.display import HTML","metadata":{"id":"mjWoZcMzMEWr","execution":{"iopub.status.busy":"2024-10-14T10:54:56.694191Z","iopub.execute_input":"2024-10-14T10:54:56.694511Z","iopub.status.idle":"2024-10-14T10:55:02.196336Z","shell.execute_reply.started":"2024-10-14T10:54:56.694476Z","shell.execute_reply":"2024-10-14T10:55:02.195472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataroot = '/kaggle/input/deepfashion-1/datasets/train_images'\n","metadata":{"id":"G-_24BoTMjaE","outputId":"2df5e52e-cae1-4b76-c6de-41471dc7b246","execution":{"iopub.status.busy":"2024-10-14T10:55:02.197675Z","iopub.execute_input":"2024-10-14T10:55:02.198079Z","iopub.status.idle":"2024-10-14T10:55:02.202107Z","shell.execute_reply.started":"2024-10-14T10:55:02.198044Z","shell.execute_reply":"2024-10-14T10:55:02.201018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nimage_files = os.listdir(dataroot)\n\nimage_files.sort()\n\nprint(image_files[-5:])\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T10:57:36.005473Z","iopub.execute_input":"2024-10-14T10:57:36.006250Z","iopub.status.idle":"2024-10-14T10:57:36.170060Z","shell.execute_reply.started":"2024-10-14T10:57:36.006210Z","shell.execute_reply":"2024-10-14T10:57:36.169212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\n\nimage_list = os.listdir(dataroot)\n\nnum_images = 5\n\nplt.figure(figsize=(15, 5))\n\nfor i in range(num_images):\n    img_path = os.path.join(dataroot, image_list[i])  # Construct full image path\n    img = cv2.imread(img_path)  # Read the image\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for proper color display\n    plt.subplot(1, num_images, i + 1)  # Create subplots\n    plt.imshow(img)  # Display the image\n    plt.axis('off')  # Hide the axis\n    plt.title(image_list[i])  # Set the title to the image file name\n\nplt.tight_layout()  # Adjust the layout\nplt.show()  # Show the plot","metadata":{"id":"jFx5tiLWNAw1","outputId":"a1ba6bfe-d5f5-464c-cb0c-c52ef52e08e7","execution":{"iopub.status.busy":"2024-10-14T10:57:50.372418Z","iopub.execute_input":"2024-10-14T10:57:50.372765Z","iopub.status.idle":"2024-10-14T10:57:51.763743Z","shell.execute_reply.started":"2024-10-14T10:57:50.372734Z","shell.execute_reply":"2024-10-14T10:57:51.762784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataroot_men = []\ndataroot_women = []\n\nfor file_name in image_files:\n    if file_name.startswith('MEN'):\n        dataroot_men.append(file_name)\n    elif file_name.startswith('WOMEN'):\n        dataroot_women.append(file_name)\n\nprint(\"MEN images:\", dataroot_men[:5])\nprint(\"WOMEN images:\", dataroot_women[:5])\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T11:00:24.503787Z","iopub.execute_input":"2024-10-14T11:00:24.504224Z","iopub.status.idle":"2024-10-14T11:00:24.517104Z","shell.execute_reply.started":"2024-10-14T11:00:24.504183Z","shell.execute_reply":"2024-10-14T11:00:24.515943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=(len(dataroot_men))\ny=(len(dataroot_women))\nprint(x+y)\nprint(len(image_files))","metadata":{"execution":{"iopub.status.busy":"2024-10-14T11:02:40.706365Z","iopub.execute_input":"2024-10-14T11:02:40.706759Z","iopub.status.idle":"2024-10-14T11:02:40.712396Z","shell.execute_reply.started":"2024-10-14T11:02:40.706724Z","shell.execute_reply":"2024-10-14T11:02:40.711302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x)\nprint(y)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T11:03:17.933178Z","iopub.execute_input":"2024-10-14T11:03:17.933565Z","iopub.status.idle":"2024-10-14T11:03:17.938771Z","shell.execute_reply.started":"2024-10-14T11:03:17.933529Z","shell.execute_reply":"2024-10-14T11:03:17.937691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nos.makedirs('/kaggle/working/data_split/MEN', exist_ok=True)\nos.makedirs('/kaggle/working/data_split/WOMEN', exist_ok=True)\n\nfor file_name in dataroot_men:\n    src_path = os.path.join(dataroot, file_name)  # Original path\n    dest_path = os.path.join('/kaggle/working/data_split/MEN', file_name)  # Destination path\n    shutil.copy(src_path, dest_path)  # You can use shutil.move to move instead of copy\n\nfor file_name in dataroot_women:\n    src_path = os.path.join(dataroot, file_name)\n    dest_path = os.path.join('/kaggle/working/data_split/WOMEN', file_name)\n    shutil.copy(src_path, dest_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T11:08:31.885652Z","iopub.execute_input":"2024-10-14T11:08:31.886536Z","iopub.status.idle":"2024-10-14T11:10:12.414092Z","shell.execute_reply.started":"2024-10-14T11:08:31.886490Z","shell.execute_reply":"2024-10-14T11:10:12.413220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"workers = 4\nbatch_size = 128\nimage_size = 64\nnc = 3\nnz = 100\nngf = 64\nndf = 64\nnum_epochs = 5\nlr = 0.0002\nbeta1 = 0.5\nngpu = 1","metadata":{"id":"2hADOkB3QCtG","execution":{"iopub.status.busy":"2024-10-14T11:04:33.535634Z","iopub.execute_input":"2024-10-14T11:04:33.536038Z","iopub.status.idle":"2024-10-14T11:04:33.541148Z","shell.execute_reply.started":"2024-10-14T11:04:33.536001Z","shell.execute_reply":"2024-10-14T11:04:33.540127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.datasets as dset\nimport torchvision.transforms as transforms\n\ndata_split_root = '/kaggle/working/data_split'\n\n# Use ImageFolder to load the dataset with transformations\ndataset = dset.ImageFolder(root=data_split_root,\n                           transform=transforms.Compose([\n                               transforms.Resize(image_size),\n                               transforms.CenterCrop(image_size),\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.5,), (0.5,)),\n                           ]))\n\n# Create DataLoader\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n                                         shuffle=True, num_workers=workers)\n\ndevice = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n\n# Check some images from the dataset\nreal_batch = next(iter(dataloader))\nplt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.title(\"Training Images\")\nplt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(), (1,2,0)))\n\n\n\n","metadata":{"id":"M5rJEyXHPlJB","outputId":"7d54610b-2da8-49dd-cf84-b4006da57b36","execution":{"iopub.status.busy":"2024-10-14T11:20:33.018928Z","iopub.execute_input":"2024-10-14T11:20:33.019737Z","iopub.status.idle":"2024-10-14T11:20:39.191080Z","shell.execute_reply.started":"2024-10-14T11:20:33.019695Z","shell.execute_reply":"2024-10-14T11:20:39.190015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)","metadata":{"id":"0NTUuTKBQHiO","execution":{"iopub.status.busy":"2024-10-14T11:20:49.251914Z","iopub.execute_input":"2024-10-14T11:20:49.252431Z","iopub.status.idle":"2024-10-14T11:20:49.258949Z","shell.execute_reply.started":"2024-10-14T11:20:49.252383Z","shell.execute_reply":"2024-10-14T11:20:49.257901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_generator(ngpu):\n    layers = []\n\n    layers.append(nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False))\n    layers.append(nn.BatchNorm2d(ngf * 8))\n    layers.append(nn.ReLU(True))\n\n    layers.append(nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False))\n    layers.append(nn.BatchNorm2d(ngf * 4))\n    layers.append(nn.ReLU(True))\n\n    layers.append(nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False))\n    layers.append(nn.BatchNorm2d(ngf * 2))\n    layers.append(nn.ReLU(True))\n\n    layers.append(nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False))\n    layers.append(nn.BatchNorm2d(ngf))\n    layers.append(nn.ReLU(True))\n\n    layers.append(nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False))\n    layers.append(nn.Tanh())\n\n    model = nn.Sequential(*layers)\n\n    return model\n\ngenerator = build_generator(ngpu)\n\ngenerator","metadata":{"id":"kmG79fgjQM2j","outputId":"99ccbc96-f1f1-4a99-fd12-889817fe8e26","execution":{"iopub.status.busy":"2024-10-14T11:20:53.489062Z","iopub.execute_input":"2024-10-14T11:20:53.489738Z","iopub.status.idle":"2024-10-14T11:20:53.531870Z","shell.execute_reply.started":"2024-10-14T11:20:53.489698Z","shell.execute_reply":"2024-10-14T11:20:53.530851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"netG = build_generator(ngpu).to(device)\n\nif (device.type == 'cuda') and (ngpu > 1):\n    netG = nn.DataParallel(netG, list(range(ngpu)))\n\nnetG.apply(weights_init)\n\nnetG","metadata":{"id":"B_-HCWldQfR4","outputId":"480ba5cc-176a-4c11-f692-57a40d510c80","execution":{"iopub.status.busy":"2024-10-14T11:21:03.232819Z","iopub.execute_input":"2024-10-14T11:21:03.233489Z","iopub.status.idle":"2024-10-14T11:21:03.277495Z","shell.execute_reply.started":"2024-10-14T11:21:03.233448Z","shell.execute_reply":"2024-10-14T11:21:03.276587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_discriminator(ngpu):\n    layers = []\n\n    layers.append(nn.Conv2d(nc, ndf, 4, 2, 1, bias=False))  # Input is (nc) x 64 x 64\n    layers.append(nn.LeakyReLU(0.2, inplace=True))\n\n    layers.append(nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False))  # State size (ndf) x 32 x 32\n    layers.append(nn.BatchNorm2d(ndf * 2))\n    layers.append(nn.LeakyReLU(0.2, inplace=True))\n\n    layers.append(nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False))  # State size (ndf*2) x 16 x 16\n    layers.append(nn.BatchNorm2d(ndf * 4))\n    layers.append(nn.LeakyReLU(0.2, inplace=True))\n\n    layers.append(nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False))  # State size (ndf*4) x 8 x 8\n    layers.append(nn.BatchNorm2d(ndf * 8))\n    layers.append(nn.LeakyReLU(0.2, inplace=True))\n\n    layers.append(nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False))  # State size (ndf*8) x 4 x 4\n    layers.append(nn.Sigmoid())  # Output layer\n\n    model = nn.Sequential(*layers)\n\n    return model\n\ndiscriminator = build_discriminator(ngpu)\n\ndiscriminator","metadata":{"id":"OlrWQvfEQlqB","outputId":"8428ac94-b71d-4a32-b0c8-23c7e309dc90","execution":{"iopub.status.busy":"2024-10-14T11:21:06.127706Z","iopub.execute_input":"2024-10-14T11:21:06.128214Z","iopub.status.idle":"2024-10-14T11:21:06.161728Z","shell.execute_reply.started":"2024-10-14T11:21:06.128175Z","shell.execute_reply":"2024-10-14T11:21:06.160912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"netD = build_discriminator(ngpu).to(device)\n\nif (device.type == 'cuda') and (ngpu > 1):\n    netD = nn.DataParallel(netD, list(range(ngpu)))\n\nnetD.apply(weights_init)\nnetD","metadata":{"id":"AYjrier5Qw4m","outputId":"ac94a1e7-1e0e-4926-885d-2c1c86c67c59","execution":{"iopub.status.busy":"2024-10-14T11:21:10.066869Z","iopub.execute_input":"2024-10-14T11:21:10.067250Z","iopub.status.idle":"2024-10-14T11:21:10.102170Z","shell.execute_reply.started":"2024-10-14T11:21:10.067214Z","shell.execute_reply":"2024-10-14T11:21:10.101330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCELoss()\n\nfixed_noise = torch.randn(64, nz, 1, 1, device=device)\n\nreal_label = 1\nfake_label = 0\n\noptimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(beta1, 0.999))\noptimizerG = optim.Adam(netG.parameters(), lr=0.001, betas=(beta1, 0.999))","metadata":{"id":"SDREFNDiQ36A","execution":{"iopub.status.busy":"2024-10-14T11:22:44.683207Z","iopub.execute_input":"2024-10-14T11:22:44.684141Z","iopub.status.idle":"2024-10-14T11:22:44.690874Z","shell.execute_reply.started":"2024-10-14T11:22:44.684098Z","shell.execute_reply":"2024-10-14T11:22:44.689769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torchvision.datasets as dset\n# import torchvision.transforms as transforms\n\n# men_data_root = '/kaggle/working/data_split/MEN'\n\n# men_dataset = dset.ImageFolder(root=men_data_root,\n#                                transform=transforms.Compose([\n#                                    transforms.Resize(image_size),\n#                                    transforms.CenterCrop(image_size),\n#                                    transforms.ToTensor(),\n#                                    transforms.Normalize((0.5,), (0.5,)),\n#                                ]))\n\n# # Create DataLoader for MEN images\n# men_dataloader = torch.utils.data.DataLoader(men_dataset, batch_size=batch_size,\n#                                              shuffle=True, num_workers=workers)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T11:17:59.826667Z","iopub.execute_input":"2024-10-14T11:17:59.827671Z","iopub.status.idle":"2024-10-14T11:17:59.832578Z","shell.execute_reply.started":"2024-10-14T11:17:59.827615Z","shell.execute_reply":"2024-10-14T11:17:59.831610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_list = []\nG_losses = []\nD_losses = []\niters = 0\nnum_epochs = 35\n\nprint(\"Starting Training Loop...\")\nfor epoch in range(num_epochs):\n    for i, data in enumerate(dataloader, 0):\n\n        netD.zero_grad()\n        real_cpu = data[0].to(device)\n        b_size = real_cpu.size(0)\n        label = torch.full((b_size,), real_label, device=device).float()  # Convert to Float\n        output = netD(real_cpu).view(-1) # 256??\n        errD_real = criterion(output, label)\n        errD_real.backward()\n        D_x = output.mean().item()\n\n        noise = torch.randn(b_size, nz, 1, 1, device=device)\n        fake = netG(noise)\n        label.fill_(fake_label)\n        output = netD(fake.detach()).view(-1)\n        errD_fake = criterion(output, label)\n        errD_fake.backward()\n        D_G_z1 = output.mean().item()\n        errD = errD_real + errD_fake\n        optimizerD.step()\n\n        netG.zero_grad()\n        label.fill_(real_label)  # fake labels are real for generator cost\n        output = netD(fake).view(-1)\n        errG = criterion(output, label)\n        errG.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n\n        if i % 50 == 0:\n            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n                  % (epoch, num_epochs, i, len(dataloader),\n                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n\n        G_losses.append(errG.item())\n        D_losses.append(errD.item())\n\n        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n            with torch.no_grad():\n                fake = netG(fixed_noise).detach().cpu()\n            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n\n        iters += 1","metadata":{"id":"I5X00-mZQ5-m","outputId":"e0adbf68-a460-49c8-c725-30bc94e42b3d","execution":{"iopub.status.busy":"2024-10-14T11:22:48.453831Z","iopub.execute_input":"2024-10-14T11:22:48.454693Z","iopub.status.idle":"2024-10-14T11:58:26.983461Z","shell.execute_reply.started":"2024-10-14T11:22:48.454650Z","shell.execute_reply":"2024-10-14T11:58:26.982155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss During Training\")\nplt.plot(G_losses,label=\"G\")\nplt.plot(D_losses,label=\"D\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"id":"myfZSTBtRHga","outputId":"8bd73013-5c19-485e-fc74-df871fe2577e","execution":{"iopub.status.busy":"2024-10-14T11:58:26.986387Z","iopub.execute_input":"2024-10-14T11:58:26.986836Z","iopub.status.idle":"2024-10-14T11:58:27.318489Z","shell.execute_reply.started":"2024-10-14T11:58:26.986788Z","shell.execute_reply":"2024-10-14T11:58:27.317505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\nani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n\nHTML(ani.to_jshtml())","metadata":{"id":"ttRq2NvlRwb1","outputId":"059704f8-4897-495a-a4ad-57b928b80fc0","execution":{"iopub.status.busy":"2024-10-14T11:58:27.319819Z","iopub.execute_input":"2024-10-14T11:58:27.320233Z","iopub.status.idle":"2024-10-14T11:58:30.420330Z","shell.execute_reply.started":"2024-10-14T11:58:27.320187Z","shell.execute_reply":"2024-10-14T11:58:30.419371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Grab a batch of real images from the dataloader\nreal_batch = next(iter(dataloader))\n\n# Plot the real images\nplt.figure(figsize=(80,80))\nplt.subplot(1,2,1)\nplt.axis(\"off\")\nplt.title(\"Real Images\")\nplt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n\n# Plot the fake images from the last epoch\nplt.subplot(1,2,2)\nplt.axis(\"off\")\nplt.title(\"Fake Images\")\nplt.imshow(np.transpose(img_list[-1],(1,2,0)))\nplt.show()","metadata":{"id":"bqoVgHnLRwnd","outputId":"de735cde-21c0-4296-94c1-d33d3d2ba23a","execution":{"iopub.status.busy":"2024-10-14T11:58:30.422406Z","iopub.execute_input":"2024-10-14T11:58:30.423050Z","iopub.status.idle":"2024-10-14T11:58:38.204469Z","shell.execute_reply.started":"2024-10-14T11:58:30.423003Z","shell.execute_reply":"2024-10-14T11:58:38.203138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save({\n    'epoch': epoch,\n    'modelG_state_dict': netG.state_dict(),\n    'modelD_state_dict': netD.state_dict(),\n    'optimizerG_state_dict': optimizerG.state_dict(),\n    'optimizerD_state_dict': optimizerD.state_dict(),\n    'G_losses': G_losses,\n    'D_losses': D_losses,\n    'iters': iters,\n}, 'gan_checkpoint.pth')\n\nprint(\"Model and optimizer states saved!\")\n","metadata":{"id":"LwQAGhD0R4as","execution":{"iopub.status.busy":"2024-10-14T12:02:46.359788Z","iopub.execute_input":"2024-10-14T12:02:46.360501Z","iopub.status.idle":"2024-10-14T12:02:46.488500Z","shell.execute_reply.started":"2024-10-14T12:02:46.360459Z","shell.execute_reply":"2024-10-14T12:02:46.487454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the saved model and optimizer states\ncheckpoint = torch.load('gan_checkpoint.pth')\nnetG.load_state_dict(checkpoint['modelG_state_dict'])\nnetD.load_state_dict(checkpoint['modelD_state_dict'])\noptimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\noptimizerD.load_state_dict(checkpoint['optimizerD_state_dict'])\n\n# Resume training settings\nG_losses = checkpoint['G_losses']\nD_losses = checkpoint['D_losses']\niters = checkpoint['iters']\nstart_epoch = checkpoint['epoch'] + 1  # Start from the next epoch\n\n# Print to confirm loading\nprint(\"Model and optimizer states loaded!\")\nprint(f\"Resuming training from epoch {start_epoch}...\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:02:59.808392Z","iopub.execute_input":"2024-10-14T12:02:59.809280Z","iopub.status.idle":"2024-10-14T12:02:59.874985Z","shell.execute_reply.started":"2024-10-14T12:02:59.809239Z","shell.execute_reply":"2024-10-14T12:02:59.874031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs_to_continue = 20 \n\nfor epoch in range(start_epoch, start_epoch + num_epochs_to_continue):\n    for i, data in enumerate(dataloader, 0):\n        netD.zero_grad()\n        real_cpu = data[0].to(device)\n        b_size = real_cpu.size(0)\n        label = torch.full((b_size,), real_label, device=device).float()  # Convert to Float\n        output = netD(real_cpu).view(-1)\n        errD_real = criterion(output, label)\n        errD_real.backward()\n        D_x = output.mean().item()\n\n        noise = torch.randn(b_size, nz, 1, 1, device=device)\n        fake = netG(noise)\n        label.fill_(fake_label)\n        output = netD(fake.detach()).view(-1)\n        errD_fake = criterion(output, label)\n        errD_fake.backward()\n        D_G_z1 = output.mean().item()\n        errD = errD_real + errD_fake\n        optimizerD.step()\n\n        netG.zero_grad()\n        label.fill_(real_label)  # fake labels are real for generator cost\n        output = netD(fake).view(-1)\n        errG = criterion(output, label)\n        errG.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n\n        if i % 50 == 0:\n            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n                  % (epoch, num_epochs_to_continue + start_epoch, i, len(dataloader),\n                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n\n        G_losses.append(errG.item())\n        D_losses.append(errD.item())\n\n        if (iters % 500 == 0) or ((epoch == start_epoch + num_epochs_to_continue - 1) and (i == len(dataloader)-1)):\n            with torch.no_grad():\n                fake = netG(fixed_noise).detach().cpu()\n            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n\n        iters += 1\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:27:29.265447Z","iopub.execute_input":"2024-10-14T12:27:29.266256Z","iopub.status.idle":"2024-10-14T12:49:58.985849Z","shell.execute_reply.started":"2024-10-14T12:27:29.266209Z","shell.execute_reply":"2024-10-14T12:49:58.982792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.animation as animation\n\ndef visualize_training(img_list, dataloader, device):\n    fig = plt.figure(figsize=(8, 8))\n    plt.axis(\"off\")\n    \n    ims = [[plt.imshow(np.transpose(i, (1, 2, 0)), animated=True)] for i in img_list]\n    ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n    display(HTML(ani.to_jshtml()))\n    \n    real_batch = next(iter(dataloader))\n    \n    plt.figure(figsize=(80, 80))\n    plt.subplot(1, 2, 1)\n    plt.axis(\"off\")\n    plt.title(\"Real Images\")\n    plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(), (1, 2, 0)))\n    \n    plt.subplot(1, 2, 2)\n    plt.axis(\"off\")\n    plt.title(\"Fake Images\")\n    if img_list:\n        plt.imshow(np.transpose(img_list[-1], (1, 2, 0)))\n    \n    plt.show()\n\nvisualize_training(img_list, dataloader, device)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:24:00.393773Z","iopub.execute_input":"2024-10-14T12:24:00.394202Z","iopub.status.idle":"2024-10-14T12:24:15.285631Z","shell.execute_reply.started":"2024-10-14T12:24:00.394160Z","shell.execute_reply":"2024-10-14T12:24:15.284486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save({\n    'epoch': epoch,\n    'modelG_state_dict': netG.state_dict(),\n    'modelD_state_dict': netD.state_dict(),\n    'optimizerG_state_dict': optimizerG.state_dict(),\n    'optimizerD_state_dict': optimizerD.state_dict(),\n    'G_losses': G_losses,\n    'D_losses': D_losses,\n    'iters': iters,\n}, 'gan_checkpoint.pth')\n\nprint(\"Model and optimizer states saved!\")\n\n# Load the saved model and optimizer states\ncheckpoint = torch.load('gan_checkpoint.pth')\nnetG.load_state_dict(checkpoint['modelG_state_dict'])\nnetD.load_state_dict(checkpoint['modelD_state_dict'])\noptimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\noptimizerD.load_state_dict(checkpoint['optimizerD_state_dict'])\n\n# Resume training settings\nG_losses = checkpoint['G_losses']\nD_losses = checkpoint['D_losses']\niters = checkpoint['iters']\nstart_epoch = checkpoint['epoch'] + 1  # Start from the next epoch\n\n# Print to confirm loading\nprint(\"Model and optimizer states loaded!\")\nprint(f\"Resuming training from epoch {start_epoch}...\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:49:58.988965Z","iopub.execute_input":"2024-10-14T12:49:58.989649Z","iopub.status.idle":"2024-10-14T12:49:59.295714Z","shell.execute_reply.started":"2024-10-14T12:49:58.989575Z","shell.execute_reply":"2024-10-14T12:49:59.294752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs_to_continue = 20  # Adjust this to the number of epochs you want to continue training\n\nfor epoch in range(start_epoch, start_epoch + num_epochs_to_continue):\n    for i, data in enumerate(dataloader, 0):\n        netD.zero_grad()\n        real_cpu = data[0].to(device)\n        b_size = real_cpu.size(0)\n        label = torch.full((b_size,), real_label, device=device).float()  # Convert to Float\n        output = netD(real_cpu).view(-1)\n        errD_real = criterion(output, label)\n        errD_real.backward()\n        D_x = output.mean().item()\n\n        noise = torch.randn(b_size, nz, 1, 1, device=device)\n        fake = netG(noise)\n        label.fill_(fake_label)\n        output = netD(fake.detach()).view(-1)\n        errD_fake = criterion(output, label)\n        errD_fake.backward()\n        D_G_z1 = output.mean().item()\n        errD = errD_real + errD_fake\n        optimizerD.step()\n\n        netG.zero_grad()\n        label.fill_(real_label)  # fake labels are real for generator cost\n        output = netD(fake).view(-1)\n        errG = criterion(output, label)\n        errG.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n\n        if i % 50 == 0:\n            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n                  % (epoch, num_epochs_to_continue + start_epoch, i, len(dataloader),\n                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n\n        G_losses.append(errG.item())\n        D_losses.append(errD.item())\n\n        if (iters % 500 == 0) or ((epoch == start_epoch + num_epochs_to_continue - 1) and (i == len(dataloader)-1)):\n            with torch.no_grad():\n                fake = netG(fixed_noise).detach().cpu()\n            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n\n        iters += 1\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T12:49:59.297030Z","iopub.execute_input":"2024-10-14T12:49:59.297342Z","iopub.status.idle":"2024-10-14T13:12:25.292496Z","shell.execute_reply.started":"2024-10-14T12:49:59.297309Z","shell.execute_reply":"2024-10-14T13:12:25.291293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training(img_list, dataloader, device)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:12:25.294886Z","iopub.execute_input":"2024-10-14T13:12:25.295264Z","iopub.status.idle":"2024-10-14T13:12:44.155901Z","shell.execute_reply.started":"2024-10-14T13:12:25.295226Z","shell.execute_reply":"2024-10-14T13:12:44.154742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save({\n    'epoch': epoch,\n    'modelG_state_dict': netG.state_dict(),\n    'modelD_state_dict': netD.state_dict(),\n    'optimizerG_state_dict': optimizerG.state_dict(),\n    'optimizerD_state_dict': optimizerD.state_dict(),\n    'G_losses': G_losses,\n    'D_losses': D_losses,\n    'iters': iters,\n}, 'gan_checkpoint.pth')\n\nprint(\"Model and optimizer states saved!\")\n\n# Load the saved model and optimizer states\ncheckpoint = torch.load('gan_checkpoint.pth')\nnetG.load_state_dict(checkpoint['modelG_state_dict'])\nnetD.load_state_dict(checkpoint['modelD_state_dict'])\noptimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\noptimizerD.load_state_dict(checkpoint['optimizerD_state_dict'])\n\n# Resume training settings\nG_losses = checkpoint['G_losses']\nD_losses = checkpoint['D_losses']\niters = checkpoint['iters']\nstart_epoch = checkpoint['epoch'] + 1  # Start from the next epoch\n\n# Print to confirm loading\nprint(\"Model and optimizer states loaded!\")\nprint(f\"Resuming training from epoch {start_epoch}...\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:12:44.157417Z","iopub.execute_input":"2024-10-14T13:12:44.157765Z","iopub.status.idle":"2024-10-14T13:12:44.425566Z","shell.execute_reply.started":"2024-10-14T13:12:44.157730Z","shell.execute_reply":"2024-10-14T13:12:44.424583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs_to_continue = 25  # Adjust this to the number of epochs you want to continue training\n\nfor epoch in range(start_epoch, start_epoch + num_epochs_to_continue):\n    for i, data in enumerate(dataloader, 0):\n        netD.zero_grad()\n        real_cpu = data[0].to(device)\n        b_size = real_cpu.size(0)\n        label = torch.full((b_size,), real_label, device=device).float()  # Convert to Float\n        output = netD(real_cpu).view(-1)\n        errD_real = criterion(output, label)\n        errD_real.backward()\n        D_x = output.mean().item()\n\n        noise = torch.randn(b_size, nz, 1, 1, device=device)\n        fake = netG(noise)\n        label.fill_(fake_label)\n        output = netD(fake.detach()).view(-1)\n        errD_fake = criterion(output, label)\n        errD_fake.backward()\n        D_G_z1 = output.mean().item()\n        errD = errD_real + errD_fake\n        optimizerD.step()\n\n        netG.zero_grad()\n        label.fill_(real_label)  # fake labels are real for generator cost\n        output = netD(fake).view(-1)\n        errG = criterion(output, label)\n        errG.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n\n        if i % 50 == 0:\n            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n                  % (epoch, num_epochs_to_continue + start_epoch, i, len(dataloader),\n                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n\n        G_losses.append(errG.item())\n        D_losses.append(errD.item())\n\n        if (iters % 500 == 0) or ((epoch == start_epoch + num_epochs_to_continue - 1) and (i == len(dataloader)-1)):\n            with torch.no_grad():\n                fake = netG(fixed_noise).detach().cpu()\n            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n\n        iters += 1\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:13:29.767069Z","iopub.execute_input":"2024-10-14T13:13:29.767515Z","iopub.status.idle":"2024-10-14T13:41:38.370181Z","shell.execute_reply.started":"2024-10-14T13:13:29.767464Z","shell.execute_reply":"2024-10-14T13:41:38.368956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training(img_list, dataloader, device)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:41:38.372833Z","iopub.execute_input":"2024-10-14T13:41:38.373632Z","iopub.status.idle":"2024-10-14T13:41:58.752520Z","shell.execute_reply.started":"2024-10-14T13:41:38.373568Z","shell.execute_reply":"2024-10-14T13:41:58.751394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save({\n    'epoch': epoch,\n    'modelG_state_dict': netG.state_dict(),\n    'modelD_state_dict': netD.state_dict(),\n    'optimizerG_state_dict': optimizerG.state_dict(),\n    'optimizerD_state_dict': optimizerD.state_dict(),\n    'G_losses': G_losses,\n    'D_losses': D_losses,\n    'iters': iters,\n}, 'gan_checkpoint.pth')\n\nprint(\"Model and optimizer states saved!\")\n\n# Load the saved model and optimizer states\ncheckpoint = torch.load('gan_checkpoint.pth')\nnetG.load_state_dict(checkpoint['modelG_state_dict'])\nnetD.load_state_dict(checkpoint['modelD_state_dict'])\noptimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\noptimizerD.load_state_dict(checkpoint['optimizerD_state_dict'])\n\n# Resume training settings\nG_losses = checkpoint['G_losses']\nD_losses = checkpoint['D_losses']\niters = checkpoint['iters']\nstart_epoch = checkpoint['epoch'] + 1  # Start from the next epoch\n\n# Print to confirm loading\nprint(\"Model and optimizer states loaded!\")\nprint(f\"Resuming training from epoch {start_epoch}...\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:41:58.754019Z","iopub.execute_input":"2024-10-14T13:41:58.754419Z","iopub.status.idle":"2024-10-14T13:41:59.042986Z","shell.execute_reply.started":"2024-10-14T13:41:58.754377Z","shell.execute_reply":"2024-10-14T13:41:59.041966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs_to_continue = 25  # Adjust this to the number of epochs you want to continue training\n\nfor epoch in range(start_epoch, start_epoch + num_epochs_to_continue):\n    for i, data in enumerate(dataloader, 0):\n        netD.zero_grad()\n        real_cpu = data[0].to(device)\n        b_size = real_cpu.size(0)\n        label = torch.full((b_size,), real_label, device=device).float()  # Convert to Float\n        output = netD(real_cpu).view(-1)\n        errD_real = criterion(output, label)\n        errD_real.backward()\n        D_x = output.mean().item()\n\n        noise = torch.randn(b_size, nz, 1, 1, device=device)\n        fake = netG(noise)\n        label.fill_(fake_label)\n        output = netD(fake.detach()).view(-1)\n        errD_fake = criterion(output, label)\n        errD_fake.backward()\n        D_G_z1 = output.mean().item()\n        errD = errD_real + errD_fake\n        optimizerD.step()\n\n        netG.zero_grad()\n        label.fill_(real_label)  # fake labels are real for generator cost\n        output = netD(fake).view(-1)\n        errG = criterion(output, label)\n        errG.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n\n        if i % 50 == 0:\n            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n                  % (epoch, num_epochs_to_continue + start_epoch, i, len(dataloader),\n                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n\n        G_losses.append(errG.item())\n        D_losses.append(errD.item())\n\n        if (iters % 500 == 0) or ((epoch == start_epoch + num_epochs_to_continue - 1) and (i == len(dataloader)-1)):\n            with torch.no_grad():\n                fake = netG(fixed_noise).detach().cpu()\n            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n\n        iters += 1\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training(img_list, dataloader, device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save({\n    'epoch': epoch,\n    'modelG_state_dict': netG.state_dict(),\n    'modelD_state_dict': netD.state_dict(),\n    'optimizerG_state_dict': optimizerG.state_dict(),\n    'optimizerD_state_dict': optimizerD.state_dict(),\n    'G_losses': G_losses,\n    'D_losses': D_losses,\n    'iters': iters,\n}, 'gan_checkpoint.pth')\n\nprint(\"Model and optimizer states saved!\")\n\n# Load the saved model and optimizer states\ncheckpoint = torch.load('gan_checkpoint.pth')\nnetG.load_state_dict(checkpoint['modelG_state_dict'])\nnetD.load_state_dict(checkpoint['modelD_state_dict'])\noptimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\noptimizerD.load_state_dict(checkpoint['optimizerD_state_dict'])\n\n# Resume training settings\nG_losses = checkpoint['G_losses']\nD_losses = checkpoint['D_losses']\niters = checkpoint['iters']\nstart_epoch = checkpoint['epoch'] + 1  # Start from the next epoch\n\n# Print to confirm loading\nprint(\"Model and optimizer states loaded!\")\nprint(f\"Resuming training from epoch {start_epoch}...\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a save path\nsave_path = './gan_model_epoch_{}.pth'  # You can change the path and filename as needed\n\n# At the end of each epoch\ntorch.save({\n    'epoch': epoch,\n    'generator_state_dict': netG.state_dict(),\n    'discriminator_state_dict': netD.state_dict(),\n    'optimizerG_state_dict': optimizerG.state_dict(),\n    'optimizerD_state_dict': optimizerD.state_dict(),\n    'G_losses': G_losses,\n    'D_losses': D_losses\n}, save_path.format(epoch))\n\nprint(f'Model saved at epoch {epoch} to {save_path.format(epoch)}')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:41:59.045643Z","iopub.execute_input":"2024-10-14T13:41:59.046484Z","iopub.status.idle":"2024-10-14T13:41:59.185493Z","shell.execute_reply.started":"2024-10-14T13:41:59.046429Z","shell.execute_reply":"2024-10-14T13:41:59.184429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_______________","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport os\n\n# Load your trained GAN model\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Load the model checkpoint\ncheckpoint = torch.load('./gan_model_epoch_99.pth', map_location=device)\n\n# Build the generator model (Ensure you have defined the build_generator function)\nnetG = build_generator(ngpu)  # Adjust ngpu according to your configuration\nnetG.load_state_dict(checkpoint['generator_state_dict'], strict=False)\nnetG.eval()\n\n# Define image size based on your model\nimage_size = 64\n\n# Function to preprocess input clothing images\ndef preprocess_image(image_path):\n    image = Image.open(image_path).convert('RGB')\n    transform = transforms.Compose([\n        transforms.Resize((image_size, image_size)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    ])\n    return transform(image).unsqueeze(0)  # Add batch dimension\n\n# Function to generate outfits\ndef generate_outfit(user_inputs):\n    processed_images = [preprocess_image(img) for img in user_inputs]\n    \n    # Create a latent vector by averaging the input images\n    latent_vector = torch.mean(torch.cat(processed_images), dim=0)\n\n    # Generate a new outfit using the GAN\n    with torch.no_grad():\n        generated_outfit = netG(latent_vector.unsqueeze(0))  # Add batch dimension\n    \n    return generated_outfit\n\n# Function to visualize and save the generated outfit\ndef visualize_and_save_outfit(outfit_tensor, save_path='generated_outfit.png'):\n    # Save the generated image\n    save_image(outfit_tensor, save_path, normalize=True)\n    \n    # Visualize the generated outfit\n    plt.figure(figsize=(8, 8))\n    plt.axis(\"off\")\n    plt.title(\"Generated Outfit\")\n    plt.imshow(np.transpose(outfit_tensor.squeeze().cpu().numpy(), (1, 2, 0)))\n    plt.show()\n\n# Main function to run the code\ndef main():\n    user_clothes = []\n\n    # For Kaggle or Colab, you can upload files from your device\n    uploaded = files.upload()  # This will prompt you to upload images from your device\n    \n    for img_name in uploaded.keys():\n        user_clothes.append(img_name)\n\n    if user_clothes:\n        outfit_image = generate_outfit(user_clothes)\n        visualize_and_save_outfit(outfit_image)\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-14T14:24:00.159836Z","iopub.execute_input":"2024-10-14T14:24:00.160868Z","iopub.status.idle":"2024-10-14T14:24:00.311774Z","shell.execute_reply.started":"2024-10-14T14:24:00.160824Z","shell.execute_reply":"2024-10-14T14:24:00.310382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_inputs = []\nnum_items = int(input(\"How many clothing items do you want to input? \"))\n\nfor _ in range(num_items):\n    img_path = input(\"Enter the path of the clothing item image: \")\n    user_inputs.append(img_path)\n\ngenerated_outfit = generate_outfit(user_inputs)\n# Proceed to visualize or save the generated outfit\n","metadata":{},"execution_count":null,"outputs":[]}]}