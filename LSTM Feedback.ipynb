{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7d80236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e70fbd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "\n",
    "# def extract_amazon_reviews(url):\n",
    "#     # Set the User-Agent to avoid being blocked by Amazon\n",
    "#     headers = {\n",
    "#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "#     }\n",
    "\n",
    "#     # Send a GET request to the product page\n",
    "#     response = requests.get(url, headers=headers)\n",
    "#     if response.status_code != 200:\n",
    "#         print(f\"Failed to retrieve the page: {response.status_code}\")\n",
    "#         return None\n",
    "\n",
    "#     # Parse the HTML content of the page\n",
    "#     soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "#     try:\n",
    "#         # Extract all reviews\n",
    "#         review_content = soup.find_all('div', class_='a-row a-spacing-small review-data')\n",
    "\n",
    "#         reviews = []  # List to store extracted reviews\n",
    "\n",
    "#         # Iterate through all reviews on the page\n",
    "#         for review in review_content:\n",
    "#             # Find the full review content\n",
    "#             full_review_text = review.find('span', {'data-hook': 'review-body'})\n",
    "#             if full_review_text:\n",
    "#                 # Clean the review text by removing \"اقرأ المزيد\" or \"see more\"\n",
    "#                 review_text = full_review_text.get_text().strip().replace(\"اقرأ المزيد\", \"\").replace(\"see more\", \"\").strip()\n",
    "#             else:\n",
    "#                 review_text = \"No review available\"\n",
    "            \n",
    "#             reviews.append(review_text)  # Append the cleaned review text to the list\n",
    "\n",
    "#         if not reviews:\n",
    "#             reviews.append(\"No reviews available\")\n",
    "\n",
    "#         # Create a DataFrame with the URL and reviews\n",
    "#         data = {\n",
    "#             'URL': [url] * len(reviews),\n",
    "#             'Review Text': reviews\n",
    "#         }\n",
    "        \n",
    "#         df = pd.DataFrame(data)\n",
    "\n",
    "#         return df\n",
    "\n",
    "#     except AttributeError as e:\n",
    "#         print(\"Error extracting details. The page structure might have changed.\")\n",
    "#         print(e)\n",
    "#         return None\n",
    "\n",
    "# # Input URL of the Amazon product page\n",
    "# url = input(\"Enter the Amazon product URL: \")\n",
    "# review_df = extract_amazon_reviews(url)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# if review_df is not None:\n",
    "#     print(\"\\nExtracted Review Details:\")\n",
    "#     print(review_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "def9f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bf9cf523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Amazon product URL: https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7%D8%A9-%D8%A8%D8%AE%D8%A7%D8%B1-%D8%AC%D8%A7%D9%81%D8%A9-%D8%A8%D8%A7%D9%86%D8%A7%D8%B3%D9%88%D9%86%D9%8A%D9%83%D8%8C-NI-M250TPTD/dp/B0B112RHBH?pd_rd_w=nZjO9&content-id=amzn1.sym.17b41c11-c8b6-40cc-b786-fe642e350c7b&pf_rd_p=17b41c11-c8b6-40cc-b786-fe642e350c7b&pf_rd_r=ZFK933NM3E1ZATNSSTD2&pd_rd_wg=uItJy&pd_rd_r=33c4fe89-5172-4226-9477-2b7e9797aabb&pd_rd_i=B0B112RHBH&ref_=pd_hp_d_btf_unk_B0B112RHBH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_27704\\1933737486.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=\"C:/Users/LENOVO/Downloads/chromedriver-win64 (1)/chromedriver-win64/chromedriver.exe\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Review Details:\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def extract_amazon_reviews(url):\n",
    "    # Initialize the WebDriver (use the path to your own ChromeDriver)\n",
    "    driver = webdriver.Chrome(executable_path=\"C:/Users/LENOVO/Downloads/chromedriver-win64 (1)/chromedriver-win64/chromedriver.exe\")\n",
    "\n",
    "    # Open the URL\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "    try:\n",
    "        reviews = []\n",
    "\n",
    "        # Extract all review elements using Selenium\n",
    "        review_elements = driver.find_elements(By.XPATH, '//div[contains(@class, \"a-row a-spacing-small review-data\")]')\n",
    "        \n",
    "        # Iterate through all reviews on the page\n",
    "        for review in review_elements:\n",
    "            full_review_text = review.find_element(By.XPATH, './/span[@data-hook=\"review-body\"]')\n",
    "            if full_review_text:\n",
    "                review_text = full_review_text.text.strip().replace(\"اقرأ المزيد\", \"\").replace(\"see more\", \"\").strip()\n",
    "                reviews.append(review_text)\n",
    "            else:\n",
    "                reviews.append(\"No review available\")\n",
    "\n",
    "        if not reviews:\n",
    "            reviews.append(\"No reviews available\")\n",
    "\n",
    "        # Create a DataFrame with the URL and reviews\n",
    "        data = {\n",
    "            'URL': [url] * len(reviews),\n",
    "            'Review Text': reviews\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error extracting details:\", e)\n",
    "        return None\n",
    "\n",
    "    finally:\n",
    "        # Close the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "# Input URL of the Amazon product page\n",
    "url = input(\"Enter the Amazon product URL: \")\n",
    "review_df = extract_amazon_reviews(url)\n",
    "\n",
    "# Display the DataFrame\n",
    "if review_df is not None:\n",
    "    print(\"\\nExtracted Review Details:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ef9d7795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...</td>\n",
       "      <td>مزاياها كتير وجميلة:\\n\\nانا بحترم المكواة اللي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...</td>\n",
       "      <td>جيدة جدا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...</td>\n",
       "      <td>خفيفه وعمليه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...</td>\n",
       "      <td>المنتج أصلي ومعاه الضمان سنه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...</td>\n",
       "      <td>حسبى اللة ونعم الوكيل لتانى مرة توصل الاوردر ب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...</td>\n",
       "      <td>As described, light, and works well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...</td>\n",
       "      <td>سعره حلو</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...</td>\n",
       "      <td>وصلتنى خفيفة فى الاستعمال وبتفرد علطول بس مش ن...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...   \n",
       "1  https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...   \n",
       "2  https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...   \n",
       "3  https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...   \n",
       "4  https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...   \n",
       "5  https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...   \n",
       "6  https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...   \n",
       "7  https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...   \n",
       "\n",
       "                                         Review Text  \n",
       "0  مزاياها كتير وجميلة:\\n\\nانا بحترم المكواة اللي...  \n",
       "1                                           جيدة جدا  \n",
       "2                                       خفيفه وعمليه  \n",
       "3                       المنتج أصلي ومعاه الضمان سنه  \n",
       "4  حسبى اللة ونعم الوكيل لتانى مرة توصل الاوردر ب...  \n",
       "5               As described, light, and works well.  \n",
       "6                                           سعره حلو  \n",
       "7  وصلتنى خفيفة فى الاستعمال وبتفرد علطول بس مش ن...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bc78ca11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a43a33c8b04fd69ce60bdef11e6a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/611 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3199c92c28554286b43db5c79f7454a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618d3a7725b044eb85f30c852a0982bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/720k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c523fc2fa82344488879cf304c2984c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdaa429f0eb48058fe5c6e06a2d41f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c1aee1f08b46a3bdb1cbe7e8e7b3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "# Install Hugging Face Transformers and PyTorch if you haven't\n",
    "# !pip install transformers torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load a pretrained sentiment analysis model (araBERT, for example)\n",
    "model_name = \"aubmindlab/bert-base-arabertv2\"  # This is the base araBERT model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Example Egyptian Arabic slang input\n",
    "text = \"الجو جميل جداً النهاردة، مبسوط قوي\"\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Get the model's prediction\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "# Convert logits to probabilities and get sentiment label\n",
    "predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "labels = ['Negative', 'Neutral', 'Positive']  # Example labels for sentiment analysis\n",
    "sentiment = labels[predicted_class]\n",
    "\n",
    "print(f\"Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f051c513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "text = review_df['Review Text'][0]\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "sentiment = labels[predicted_class]\n",
    "\n",
    "print(f\"Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9cc5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3be6012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    model_name = \"aubmindlab/bert-base-arabertv2\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "    labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "    sentiment = labels[predicted_class]\n",
    "    if sentiment == 'Neutral':\n",
    "        sentiment = 'Positive'\n",
    "\n",
    "    return sentiment\n",
    "\n",
    "# Example usage\n",
    "text_input =  review_df['Review Text'][7]\n",
    "sentiment_result = analyze_sentiment(text_input)\n",
    "print(f\"Sentiment: {sentiment_result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a7bbdeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_and_analyze(url):\n",
    "    review_df = extract_amazon_reviews(url)\n",
    "    \n",
    "    if review_df is not None:\n",
    "        review_df['Sentiment'] = review_df['Review Text'].apply(analyze_sentiment)\n",
    "        return review_df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Input URL of the Amazon product page\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "09558189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Amazon product URL: https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7%D8%B1%D9%8A%D8%A9-5000mAh-%D9%88%D8%B4%D8%B1%D9%8A%D8%AD%D8%AA%D9%8A%D9%86-%D9%88%D9%83%D8%A7%D9%85%D9%8A%D8%B1%D8%A7-%D9%88%D8%A7%D9%86%D9%8A%D9%82%D8%A9%D8%8C/product-reviews/B0CZRYT5XZ/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_27704\\1933737486.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=\"C:/Users/LENOVO/Downloads/chromedriver-win64 (1)/chromedriver-win64/chromedriver.exe\")\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>المنتج غلط</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>الفون وصل اخيرا. كويس كموبيل تاني</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>أنا لم أستلم المنتج ولم أتلقي أي رسالة أو اتصا...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>اريد معرفه نوع الضمان محلي ام دولي ؟</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>هل يوجد ضمان ؟</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>رغم فخامة شكلة الا انه يخدعك معقول فى اجهزة بت...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>المنتج لم يصلني اين المنتج</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>👍</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>Vino el cable pero no el cargador</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>EXCELENTE LLEGO A MIS MANOS ANTES DE LO PREVISTO</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "1  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "2  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "3  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "4  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "5  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "6  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "7  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "8  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "9  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "\n",
       "                                         Review Text Sentiment  \n",
       "0                                         المنتج غلط  Positive  \n",
       "1                  الفون وصل اخيرا. كويس كموبيل تاني  Negative  \n",
       "2  أنا لم أستلم المنتج ولم أتلقي أي رسالة أو اتصا...  Negative  \n",
       "3               اريد معرفه نوع الضمان محلي ام دولي ؟  Positive  \n",
       "4                                     هل يوجد ضمان ؟  Positive  \n",
       "5  رغم فخامة شكلة الا انه يخدعك معقول فى اجهزة بت...  Negative  \n",
       "6                         المنتج لم يصلني اين المنتج  Positive  \n",
       "7                                                  👍  Negative  \n",
       "8                  Vino el cable pero no el cargador  Positive  \n",
       "9   EXCELENTE LLEGO A MIS MANOS ANTES DE LO PREVISTO  Negative  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = input(\"Enter the Amazon product URL: \")\n",
    "result_df = scrape_and_analyze(url)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6ef83199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_and_analyze(url):\n",
    "    review_df = extract_amazon_reviews(url)\n",
    "    \n",
    "    if review_df is not None:\n",
    "        review_df['Sentiment'] = review_df['Review Text'].apply(analyze_sentiment)\n",
    "        \n",
    "        total_reviews = len(review_df)\n",
    "        positive_reviews = len(review_df[review_df['Sentiment'] == 'Positive'])\n",
    "        positive_percentage = (positive_reviews / total_reviews) * 100 if total_reviews > 0 else 0\n",
    "        \n",
    "        return review_df, positive_percentage\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1b198014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Amazon product URL: https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1-%D8%A7%D9%84%D8%A7%D8%B1%D8%AA%D8%AF%D8%A7%D8%A1-%D9%84%D9%84%D8%B1%D8%AC%D8%A7%D9%84-%D9%85%D9%8A%D9%86%D8%AA%D8%B1%D8%A7%D8%8C-%D8%A3%D8%A8%D9%8A%D8%B6%D8%8C/dp/B0BYJV86ZZ?pd_rd_w=9cv6v&content-id=amzn1.sym.17b41c11-c8b6-40cc-b786-fe642e350c7b&pf_rd_p=17b41c11-c8b6-40cc-b786-fe642e350c7b&pf_rd_r=4RVR07ASND9D1DM1XJ36&pd_rd_wg=MOjeh&pd_rd_r=86332a0a-5cf7-4b0d-aff6-18c996d0debf&pd_rd_i=B0BYJV86ZZ&ref_=pd_hp_d_btf_unk_B0BYJV86ZZ&th=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_27704\\1933737486.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=\"C:/Users/LENOVO/Downloads/chromedriver-win64 (1)/chromedriver-win64/chromedriver.exe\")\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>كنت قلقان جدا لأن ليا تجربة قبل كده مع اقل الم...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>خفيف و عملى و التقفيل جيد جدا</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>فعلاً خامة كويسة َ تقفيل كويس جداً.\\nخد كاتب ا...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>حاول تجيب مقاس اصغر نمرة من تلبيسك لان تلبيسه ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>منتج مريح وخفيف في الرجل</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>المقاس مش مظبوط ولازم تطلب نمرة اقل من مقاسك ا...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>خامه ممتازه وخفيف ومريح بس المقاس صغير\\nاشتريت...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>خامه وتقفيل خفيف تنصح به لكن المقاس كبير اختار...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>This merchandise was priced at a good price it...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>Wow, better fit and even more comfortable than...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>Great fitting shoe .. light weight very comfor...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>I ordered a 10.5 wide set of these but I could...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>The shoes seemed like a shoe made from an inte...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  URL  \\\n",
       "0   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "1   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "2   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "3   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "4   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "5   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "6   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "7   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "8   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "9   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "10  https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "11  https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "12  https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "\n",
       "                                          Review Text Sentiment  \n",
       "0   كنت قلقان جدا لأن ليا تجربة قبل كده مع اقل الم...  Negative  \n",
       "1                       خفيف و عملى و التقفيل جيد جدا  Positive  \n",
       "2   فعلاً خامة كويسة َ تقفيل كويس جداً.\\nخد كاتب ا...  Negative  \n",
       "3   حاول تجيب مقاس اصغر نمرة من تلبيسك لان تلبيسه ...  Negative  \n",
       "4                            منتج مريح وخفيف في الرجل  Negative  \n",
       "5   المقاس مش مظبوط ولازم تطلب نمرة اقل من مقاسك ا...  Negative  \n",
       "6   خامه ممتازه وخفيف ومريح بس المقاس صغير\\nاشتريت...  Negative  \n",
       "7   خامه وتقفيل خفيف تنصح به لكن المقاس كبير اختار...  Negative  \n",
       "8   This merchandise was priced at a good price it...  Positive  \n",
       "9   Wow, better fit and even more comfortable than...  Positive  \n",
       "10  Great fitting shoe .. light weight very comfor...  Negative  \n",
       "11  I ordered a 10.5 wide set of these but I could...  Positive  \n",
       "12  The shoes seemed like a shoe made from an inte...  Negative  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = input(\"Enter the Amazon product URL: \")\n",
    "result_df,percent = scrape_and_analyze(url)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f230729d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.76923076923077"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fa9684fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function saved as 'scrape_and_analyze.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('scrape_and_analyze.pkl', 'wb') as f:\n",
    "    pickle.dump(scrape_and_analyze, f)\n",
    "\n",
    "print(\"Function saved as 'scrape_and_analyze.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef010813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
