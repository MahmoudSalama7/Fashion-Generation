{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7d80236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e70fbd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "\n",
    "# def extract_amazon_reviews(url):\n",
    "#     # Set the User-Agent to avoid being blocked by Amazon\n",
    "#     headers = {\n",
    "#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "#     }\n",
    "\n",
    "#     # Send a GET request to the product page\n",
    "#     response = requests.get(url, headers=headers)\n",
    "#     if response.status_code != 200:\n",
    "#         print(f\"Failed to retrieve the page: {response.status_code}\")\n",
    "#         return None\n",
    "\n",
    "#     # Parse the HTML content of the page\n",
    "#     soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "#     try:\n",
    "#         # Extract all reviews\n",
    "#         review_content = soup.find_all('div', class_='a-row a-spacing-small review-data')\n",
    "\n",
    "#         reviews = []  # List to store extracted reviews\n",
    "\n",
    "#         # Iterate through all reviews on the page\n",
    "#         for review in review_content:\n",
    "#             # Find the full review content\n",
    "#             full_review_text = review.find('span', {'data-hook': 'review-body'})\n",
    "#             if full_review_text:\n",
    "#                 # Clean the review text by removing \"Ø§Ù‚Ø±Ø£ Ø§Ù„Ù…Ø²ÙŠØ¯\" or \"see more\"\n",
    "#                 review_text = full_review_text.get_text().strip().replace(\"Ø§Ù‚Ø±Ø£ Ø§Ù„Ù…Ø²ÙŠØ¯\", \"\").replace(\"see more\", \"\").strip()\n",
    "#             else:\n",
    "#                 review_text = \"No review available\"\n",
    "            \n",
    "#             reviews.append(review_text)  # Append the cleaned review text to the list\n",
    "\n",
    "#         if not reviews:\n",
    "#             reviews.append(\"No reviews available\")\n",
    "\n",
    "#         # Create a DataFrame with the URL and reviews\n",
    "#         data = {\n",
    "#             'URL': [url] * len(reviews),\n",
    "#             'Review Text': reviews\n",
    "#         }\n",
    "        \n",
    "#         df = pd.DataFrame(data)\n",
    "\n",
    "#         return df\n",
    "\n",
    "#     except AttributeError as e:\n",
    "#         print(\"Error extracting details. The page structure might have changed.\")\n",
    "#         print(e)\n",
    "#         return None\n",
    "\n",
    "# # Input URL of the Amazon product page\n",
    "# url = input(\"Enter the Amazon product URL: \")\n",
    "# review_df = extract_amazon_reviews(url)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# if review_df is not None:\n",
    "#     print(\"\\nExtracted Review Details:\")\n",
    "#     print(review_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "def9f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bf9cf523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Amazon product URL: https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7%D8%A9-%D8%A8%D8%AE%D8%A7%D8%B1-%D8%AC%D8%A7%D9%81%D8%A9-%D8%A8%D8%A7%D9%86%D8%A7%D8%B3%D9%88%D9%86%D9%8A%D9%83%D8%8C-NI-M250TPTD/dp/B0B112RHBH?pd_rd_w=nZjO9&content-id=amzn1.sym.17b41c11-c8b6-40cc-b786-fe642e350c7b&pf_rd_p=17b41c11-c8b6-40cc-b786-fe642e350c7b&pf_rd_r=ZFK933NM3E1ZATNSSTD2&pd_rd_wg=uItJy&pd_rd_r=33c4fe89-5172-4226-9477-2b7e9797aabb&pd_rd_i=B0B112RHBH&ref_=pd_hp_d_btf_unk_B0B112RHBH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_27704\\1933737486.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=\"C:/Users/LENOVO/Downloads/chromedriver-win64 (1)/chromedriver-win64/chromedriver.exe\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Review Details:\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def extract_amazon_reviews(url):\n",
    "    # Initialize the WebDriver (use the path to your own ChromeDriver)\n",
    "    driver = webdriver.Chrome(executable_path=\"C:/Users/LENOVO/Downloads/chromedriver-win64 (1)/chromedriver-win64/chromedriver.exe\")\n",
    "\n",
    "    # Open the URL\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "    try:\n",
    "        reviews = []\n",
    "\n",
    "        # Extract all review elements using Selenium\n",
    "        review_elements = driver.find_elements(By.XPATH, '//div[contains(@class, \"a-row a-spacing-small review-data\")]')\n",
    "        \n",
    "        # Iterate through all reviews on the page\n",
    "        for review in review_elements:\n",
    "            full_review_text = review.find_element(By.XPATH, './/span[@data-hook=\"review-body\"]')\n",
    "            if full_review_text:\n",
    "                review_text = full_review_text.text.strip().replace(\"Ø§Ù‚Ø±Ø£ Ø§Ù„Ù…Ø²ÙŠØ¯\", \"\").replace(\"see more\", \"\").strip()\n",
    "                reviews.append(review_text)\n",
    "            else:\n",
    "                reviews.append(\"No review available\")\n",
    "\n",
    "        if not reviews:\n",
    "            reviews.append(\"No reviews available\")\n",
    "\n",
    "        # Create a DataFrame with the URL and reviews\n",
    "        data = {\n",
    "            'URL': [url] * len(reviews),\n",
    "            'Review Text': reviews\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error extracting details:\", e)\n",
    "        return None\n",
    "\n",
    "    finally:\n",
    "        # Close the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "# Input URL of the Amazon product page\n",
    "url = input(\"Enter the Amazon product URL: \")\n",
    "review_df = extract_amazon_reviews(url)\n",
    "\n",
    "# Display the DataFrame\n",
    "if review_df is not None:\n",
    "    print(\"\\nExtracted Review Details:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ef9d7795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...</td>\n",
       "      <td>Ù…Ø²Ø§ÙŠØ§Ù‡Ø§ ÙƒØªÙŠØ± ÙˆØ¬Ù…ÙŠÙ„Ø©:\\n\\nØ§Ù†Ø§ Ø¨Ø­ØªØ±Ù… Ø§Ù„Ù…ÙƒÙˆØ§Ø© Ø§Ù„Ù„ÙŠ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...</td>\n",
       "      <td>Ø¬ÙŠØ¯Ø© Ø¬Ø¯Ø§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...</td>\n",
       "      <td>Ø®ÙÙŠÙÙ‡ ÙˆØ¹Ù…Ù„ÙŠÙ‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...</td>\n",
       "      <td>Ø§Ù„Ù…Ù†ØªØ¬ Ø£ØµÙ„ÙŠ ÙˆÙ…Ø¹Ø§Ù‡ Ø§Ù„Ø¶Ù…Ø§Ù† Ø³Ù†Ù‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...</td>\n",
       "      <td>Ø­Ø³Ø¨Ù‰ Ø§Ù„Ù„Ø© ÙˆÙ†Ø¹Ù… Ø§Ù„ÙˆÙƒÙŠÙ„ Ù„ØªØ§Ù†Ù‰ Ù…Ø±Ø© ØªÙˆØµÙ„ Ø§Ù„Ø§ÙˆØ±Ø¯Ø± Ø¨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...</td>\n",
       "      <td>As described, light, and works well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...</td>\n",
       "      <td>Ø³Ø¹Ø±Ù‡ Ø­Ù„Ùˆ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...</td>\n",
       "      <td>ÙˆØµÙ„ØªÙ†Ù‰ Ø®ÙÙŠÙØ© ÙÙ‰ Ø§Ù„Ø§Ø³ØªØ¹Ù…Ø§Ù„ ÙˆØ¨ØªÙØ±Ø¯ Ø¹Ù„Ø·ÙˆÙ„ Ø¨Ø³ Ù…Ø´ Ù†...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...   \n",
       "1  https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...   \n",
       "2  https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...   \n",
       "3  https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...   \n",
       "4  https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...   \n",
       "5  https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...   \n",
       "6  https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...   \n",
       "7  https://www.amazon.eg/%D9%85%D9%83%D9%88%D8%A7...   \n",
       "\n",
       "                                         Review Text  \n",
       "0  Ù…Ø²Ø§ÙŠØ§Ù‡Ø§ ÙƒØªÙŠØ± ÙˆØ¬Ù…ÙŠÙ„Ø©:\\n\\nØ§Ù†Ø§ Ø¨Ø­ØªØ±Ù… Ø§Ù„Ù…ÙƒÙˆØ§Ø© Ø§Ù„Ù„ÙŠ...  \n",
       "1                                           Ø¬ÙŠØ¯Ø© Ø¬Ø¯Ø§  \n",
       "2                                       Ø®ÙÙŠÙÙ‡ ÙˆØ¹Ù…Ù„ÙŠÙ‡  \n",
       "3                       Ø§Ù„Ù…Ù†ØªØ¬ Ø£ØµÙ„ÙŠ ÙˆÙ…Ø¹Ø§Ù‡ Ø§Ù„Ø¶Ù…Ø§Ù† Ø³Ù†Ù‡  \n",
       "4  Ø­Ø³Ø¨Ù‰ Ø§Ù„Ù„Ø© ÙˆÙ†Ø¹Ù… Ø§Ù„ÙˆÙƒÙŠÙ„ Ù„ØªØ§Ù†Ù‰ Ù…Ø±Ø© ØªÙˆØµÙ„ Ø§Ù„Ø§ÙˆØ±Ø¯Ø± Ø¨...  \n",
       "5               As described, light, and works well.  \n",
       "6                                           Ø³Ø¹Ø±Ù‡ Ø­Ù„Ùˆ  \n",
       "7  ÙˆØµÙ„ØªÙ†Ù‰ Ø®ÙÙŠÙØ© ÙÙ‰ Ø§Ù„Ø§Ø³ØªØ¹Ù…Ø§Ù„ ÙˆØ¨ØªÙØ±Ø¯ Ø¹Ù„Ø·ÙˆÙ„ Ø¨Ø³ Ù…Ø´ Ù†...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bc78ca11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a43a33c8b04fd69ce60bdef11e6a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/611 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3199c92c28554286b43db5c79f7454a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618d3a7725b044eb85f30c852a0982bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/720k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c523fc2fa82344488879cf304c2984c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdaa429f0eb48058fe5c6e06a2d41f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c1aee1f08b46a3bdb1cbe7e8e7b3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "# Install Hugging Face Transformers and PyTorch if you haven't\n",
    "# !pip install transformers torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load a pretrained sentiment analysis model (araBERT, for example)\n",
    "model_name = \"aubmindlab/bert-base-arabertv2\"  # This is the base araBERT model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Example Egyptian Arabic slang input\n",
    "text = \"Ø§Ù„Ø¬Ùˆ Ø¬Ù…ÙŠÙ„ Ø¬Ø¯Ø§Ù‹ Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ø©ØŒ Ù…Ø¨Ø³ÙˆØ· Ù‚ÙˆÙŠ\"\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Get the model's prediction\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "# Convert logits to probabilities and get sentiment label\n",
    "predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "labels = ['Negative', 'Neutral', 'Positive']  # Example labels for sentiment analysis\n",
    "sentiment = labels[predicted_class]\n",
    "\n",
    "print(f\"Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f051c513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "text = review_df['Review Text'][0]\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "sentiment = labels[predicted_class]\n",
    "\n",
    "print(f\"Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9cc5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3be6012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    model_name = \"aubmindlab/bert-base-arabertv2\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "    labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "    sentiment = labels[predicted_class]\n",
    "    if sentiment == 'Neutral':\n",
    "        sentiment = 'Positive'\n",
    "\n",
    "    return sentiment\n",
    "\n",
    "# Example usage\n",
    "text_input =  review_df['Review Text'][7]\n",
    "sentiment_result = analyze_sentiment(text_input)\n",
    "print(f\"Sentiment: {sentiment_result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a7bbdeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_and_analyze(url):\n",
    "    review_df = extract_amazon_reviews(url)\n",
    "    \n",
    "    if review_df is not None:\n",
    "        review_df['Sentiment'] = review_df['Review Text'].apply(analyze_sentiment)\n",
    "        return review_df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Input URL of the Amazon product page\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "09558189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Amazon product URL: https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7%D8%B1%D9%8A%D8%A9-5000mAh-%D9%88%D8%B4%D8%B1%D9%8A%D8%AD%D8%AA%D9%8A%D9%86-%D9%88%D9%83%D8%A7%D9%85%D9%8A%D8%B1%D8%A7-%D9%88%D8%A7%D9%86%D9%8A%D9%82%D8%A9%D8%8C/product-reviews/B0CZRYT5XZ/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_27704\\1933737486.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=\"C:/Users/LENOVO/Downloads/chromedriver-win64 (1)/chromedriver-win64/chromedriver.exe\")\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>Ø§Ù„Ù…Ù†ØªØ¬ ØºÙ„Ø·</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>Ø§Ù„ÙÙˆÙ† ÙˆØµÙ„ Ø§Ø®ÙŠØ±Ø§. ÙƒÙˆÙŠØ³ ÙƒÙ…ÙˆØ¨ÙŠÙ„ ØªØ§Ù†ÙŠ</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>Ø£Ù†Ø§ Ù„Ù… Ø£Ø³ØªÙ„Ù… Ø§Ù„Ù…Ù†ØªØ¬ ÙˆÙ„Ù… Ø£ØªÙ„Ù‚ÙŠ Ø£ÙŠ Ø±Ø³Ø§Ù„Ø© Ø£Ùˆ Ø§ØªØµØ§...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>Ø§Ø±ÙŠØ¯ Ù…Ø¹Ø±ÙÙ‡ Ù†ÙˆØ¹ Ø§Ù„Ø¶Ù…Ø§Ù† Ù…Ø­Ù„ÙŠ Ø§Ù… Ø¯ÙˆÙ„ÙŠ ØŸ</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>Ù‡Ù„ ÙŠÙˆØ¬Ø¯ Ø¶Ù…Ø§Ù† ØŸ</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>Ø±ØºÙ… ÙØ®Ø§Ù…Ø© Ø´ÙƒÙ„Ø© Ø§Ù„Ø§ Ø§Ù†Ù‡ ÙŠØ®Ø¯Ø¹Ùƒ Ù…Ø¹Ù‚ÙˆÙ„ ÙÙ‰ Ø§Ø¬Ù‡Ø²Ø© Ø¨Øª...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>Ø§Ù„Ù…Ù†ØªØ¬ Ù„Ù… ÙŠØµÙ„Ù†ÙŠ Ø§ÙŠÙ† Ø§Ù„Ù…Ù†ØªØ¬</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>ğŸ‘</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>Vino el cable pero no el cargador</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...</td>\n",
       "      <td>EXCELENTE LLEGO A MIS MANOS ANTES DE LO PREVISTO</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "1  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "2  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "3  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "4  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "5  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "6  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "7  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "8  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "9  https://www.amazon.eg/%D9%88%D8%A8%D8%B7%D8%A7...   \n",
       "\n",
       "                                         Review Text Sentiment  \n",
       "0                                         Ø§Ù„Ù…Ù†ØªØ¬ ØºÙ„Ø·  Positive  \n",
       "1                  Ø§Ù„ÙÙˆÙ† ÙˆØµÙ„ Ø§Ø®ÙŠØ±Ø§. ÙƒÙˆÙŠØ³ ÙƒÙ…ÙˆØ¨ÙŠÙ„ ØªØ§Ù†ÙŠ  Negative  \n",
       "2  Ø£Ù†Ø§ Ù„Ù… Ø£Ø³ØªÙ„Ù… Ø§Ù„Ù…Ù†ØªØ¬ ÙˆÙ„Ù… Ø£ØªÙ„Ù‚ÙŠ Ø£ÙŠ Ø±Ø³Ø§Ù„Ø© Ø£Ùˆ Ø§ØªØµØ§...  Negative  \n",
       "3               Ø§Ø±ÙŠØ¯ Ù…Ø¹Ø±ÙÙ‡ Ù†ÙˆØ¹ Ø§Ù„Ø¶Ù…Ø§Ù† Ù…Ø­Ù„ÙŠ Ø§Ù… Ø¯ÙˆÙ„ÙŠ ØŸ  Positive  \n",
       "4                                     Ù‡Ù„ ÙŠÙˆØ¬Ø¯ Ø¶Ù…Ø§Ù† ØŸ  Positive  \n",
       "5  Ø±ØºÙ… ÙØ®Ø§Ù…Ø© Ø´ÙƒÙ„Ø© Ø§Ù„Ø§ Ø§Ù†Ù‡ ÙŠØ®Ø¯Ø¹Ùƒ Ù…Ø¹Ù‚ÙˆÙ„ ÙÙ‰ Ø§Ø¬Ù‡Ø²Ø© Ø¨Øª...  Negative  \n",
       "6                         Ø§Ù„Ù…Ù†ØªØ¬ Ù„Ù… ÙŠØµÙ„Ù†ÙŠ Ø§ÙŠÙ† Ø§Ù„Ù…Ù†ØªØ¬  Positive  \n",
       "7                                                  ğŸ‘  Negative  \n",
       "8                  Vino el cable pero no el cargador  Positive  \n",
       "9   EXCELENTE LLEGO A MIS MANOS ANTES DE LO PREVISTO  Negative  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = input(\"Enter the Amazon product URL: \")\n",
    "result_df = scrape_and_analyze(url)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6ef83199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_and_analyze(url):\n",
    "    review_df = extract_amazon_reviews(url)\n",
    "    \n",
    "    if review_df is not None:\n",
    "        review_df['Sentiment'] = review_df['Review Text'].apply(analyze_sentiment)\n",
    "        \n",
    "        total_reviews = len(review_df)\n",
    "        positive_reviews = len(review_df[review_df['Sentiment'] == 'Positive'])\n",
    "        positive_percentage = (positive_reviews / total_reviews) * 100 if total_reviews > 0 else 0\n",
    "        \n",
    "        return review_df, positive_percentage\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1b198014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Amazon product URL: https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1-%D8%A7%D9%84%D8%A7%D8%B1%D8%AA%D8%AF%D8%A7%D8%A1-%D9%84%D9%84%D8%B1%D8%AC%D8%A7%D9%84-%D9%85%D9%8A%D9%86%D8%AA%D8%B1%D8%A7%D8%8C-%D8%A3%D8%A8%D9%8A%D8%B6%D8%8C/dp/B0BYJV86ZZ?pd_rd_w=9cv6v&content-id=amzn1.sym.17b41c11-c8b6-40cc-b786-fe642e350c7b&pf_rd_p=17b41c11-c8b6-40cc-b786-fe642e350c7b&pf_rd_r=4RVR07ASND9D1DM1XJ36&pd_rd_wg=MOjeh&pd_rd_r=86332a0a-5cf7-4b0d-aff6-18c996d0debf&pd_rd_i=B0BYJV86ZZ&ref_=pd_hp_d_btf_unk_B0BYJV86ZZ&th=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_27704\\1933737486.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=\"C:/Users/LENOVO/Downloads/chromedriver-win64 (1)/chromedriver-win64/chromedriver.exe\")\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>ÙƒÙ†Øª Ù‚Ù„Ù‚Ø§Ù† Ø¬Ø¯Ø§ Ù„Ø£Ù† Ù„ÙŠØ§ ØªØ¬Ø±Ø¨Ø© Ù‚Ø¨Ù„ ÙƒØ¯Ù‡ Ù…Ø¹ Ø§Ù‚Ù„ Ø§Ù„Ù…...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>Ø®ÙÙŠÙ Ùˆ Ø¹Ù…Ù„Ù‰ Ùˆ Ø§Ù„ØªÙ‚ÙÙŠÙ„ Ø¬ÙŠØ¯ Ø¬Ø¯Ø§</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>ÙØ¹Ù„Ø§Ù‹ Ø®Ø§Ù…Ø© ÙƒÙˆÙŠØ³Ø© Ù ØªÙ‚ÙÙŠÙ„ ÙƒÙˆÙŠØ³ Ø¬Ø¯Ø§Ù‹.\\nØ®Ø¯ ÙƒØ§ØªØ¨ Ø§...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>Ø­Ø§ÙˆÙ„ ØªØ¬ÙŠØ¨ Ù…Ù‚Ø§Ø³ Ø§ØµØºØ± Ù†Ù…Ø±Ø© Ù…Ù† ØªÙ„Ø¨ÙŠØ³Ùƒ Ù„Ø§Ù† ØªÙ„Ø¨ÙŠØ³Ù‡ ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>Ù…Ù†ØªØ¬ Ù…Ø±ÙŠØ­ ÙˆØ®ÙÙŠÙ ÙÙŠ Ø§Ù„Ø±Ø¬Ù„</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>Ø§Ù„Ù…Ù‚Ø§Ø³ Ù…Ø´ Ù…Ø¸Ø¨ÙˆØ· ÙˆÙ„Ø§Ø²Ù… ØªØ·Ù„Ø¨ Ù†Ù…Ø±Ø© Ø§Ù‚Ù„ Ù…Ù† Ù…Ù‚Ø§Ø³Ùƒ Ø§...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>Ø®Ø§Ù…Ù‡ Ù…Ù…ØªØ§Ø²Ù‡ ÙˆØ®ÙÙŠÙ ÙˆÙ…Ø±ÙŠØ­ Ø¨Ø³ Ø§Ù„Ù…Ù‚Ø§Ø³ ØµØºÙŠØ±\\nØ§Ø´ØªØ±ÙŠØª...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>Ø®Ø§Ù…Ù‡ ÙˆØªÙ‚ÙÙŠÙ„ Ø®ÙÙŠÙ ØªÙ†ØµØ­ Ø¨Ù‡ Ù„ÙƒÙ† Ø§Ù„Ù…Ù‚Ø§Ø³ ÙƒØ¨ÙŠØ± Ø§Ø®ØªØ§Ø±...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>This merchandise was priced at a good price it...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>Wow, better fit and even more comfortable than...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>Great fitting shoe .. light weight very comfor...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>I ordered a 10.5 wide set of these but I could...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...</td>\n",
       "      <td>The shoes seemed like a shoe made from an inte...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  URL  \\\n",
       "0   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "1   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "2   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "3   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "4   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "5   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "6   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "7   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "8   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "9   https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "10  https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "11  https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "12  https://www.amazon.eg/%D8%AD%D8%B0%D8%A7%D8%A1...   \n",
       "\n",
       "                                          Review Text Sentiment  \n",
       "0   ÙƒÙ†Øª Ù‚Ù„Ù‚Ø§Ù† Ø¬Ø¯Ø§ Ù„Ø£Ù† Ù„ÙŠØ§ ØªØ¬Ø±Ø¨Ø© Ù‚Ø¨Ù„ ÙƒØ¯Ù‡ Ù…Ø¹ Ø§Ù‚Ù„ Ø§Ù„Ù…...  Negative  \n",
       "1                       Ø®ÙÙŠÙ Ùˆ Ø¹Ù…Ù„Ù‰ Ùˆ Ø§Ù„ØªÙ‚ÙÙŠÙ„ Ø¬ÙŠØ¯ Ø¬Ø¯Ø§  Positive  \n",
       "2   ÙØ¹Ù„Ø§Ù‹ Ø®Ø§Ù…Ø© ÙƒÙˆÙŠØ³Ø© Ù ØªÙ‚ÙÙŠÙ„ ÙƒÙˆÙŠØ³ Ø¬Ø¯Ø§Ù‹.\\nØ®Ø¯ ÙƒØ§ØªØ¨ Ø§...  Negative  \n",
       "3   Ø­Ø§ÙˆÙ„ ØªØ¬ÙŠØ¨ Ù…Ù‚Ø§Ø³ Ø§ØµØºØ± Ù†Ù…Ø±Ø© Ù…Ù† ØªÙ„Ø¨ÙŠØ³Ùƒ Ù„Ø§Ù† ØªÙ„Ø¨ÙŠØ³Ù‡ ...  Negative  \n",
       "4                            Ù…Ù†ØªØ¬ Ù…Ø±ÙŠØ­ ÙˆØ®ÙÙŠÙ ÙÙŠ Ø§Ù„Ø±Ø¬Ù„  Negative  \n",
       "5   Ø§Ù„Ù…Ù‚Ø§Ø³ Ù…Ø´ Ù…Ø¸Ø¨ÙˆØ· ÙˆÙ„Ø§Ø²Ù… ØªØ·Ù„Ø¨ Ù†Ù…Ø±Ø© Ø§Ù‚Ù„ Ù…Ù† Ù…Ù‚Ø§Ø³Ùƒ Ø§...  Negative  \n",
       "6   Ø®Ø§Ù…Ù‡ Ù…Ù…ØªØ§Ø²Ù‡ ÙˆØ®ÙÙŠÙ ÙˆÙ…Ø±ÙŠØ­ Ø¨Ø³ Ø§Ù„Ù…Ù‚Ø§Ø³ ØµØºÙŠØ±\\nØ§Ø´ØªØ±ÙŠØª...  Negative  \n",
       "7   Ø®Ø§Ù…Ù‡ ÙˆØªÙ‚ÙÙŠÙ„ Ø®ÙÙŠÙ ØªÙ†ØµØ­ Ø¨Ù‡ Ù„ÙƒÙ† Ø§Ù„Ù…Ù‚Ø§Ø³ ÙƒØ¨ÙŠØ± Ø§Ø®ØªØ§Ø±...  Negative  \n",
       "8   This merchandise was priced at a good price it...  Positive  \n",
       "9   Wow, better fit and even more comfortable than...  Positive  \n",
       "10  Great fitting shoe .. light weight very comfor...  Negative  \n",
       "11  I ordered a 10.5 wide set of these but I could...  Positive  \n",
       "12  The shoes seemed like a shoe made from an inte...  Negative  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = input(\"Enter the Amazon product URL: \")\n",
    "result_df,percent = scrape_and_analyze(url)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f230729d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.76923076923077"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fa9684fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function saved as 'scrape_and_analyze.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('scrape_and_analyze.pkl', 'wb') as f:\n",
    "    pickle.dump(scrape_and_analyze, f)\n",
    "\n",
    "print(\"Function saved as 'scrape_and_analyze.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef010813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
